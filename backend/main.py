from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os  # .envìš©
from dotenv import load_dotenv  # .envìš©
import torch
# (!!) Image-to-Image íŒŒì´í”„ë¼ì¸ìœ¼ë¡œ ë³€ê²½
from diffusers import StableDiffusionImg2ImgPipeline
from transformers import AutoTokenizer, AutoModelForCausalLM
import base64
from io import BytesIO
import asyncio
import databases
import sqlalchemy
from PIL import Image # <-- ì´ë¯¸ì§€ ì²˜ë¦¬ìš©
from rembg import remove # <-- ë°°ê²½ ì œê±°ìš©

# --- 1. Cafe24 DB (MySQL) ì„¤ì • (ë³´ì•ˆ ê°•í™”!) ---
load_dotenv() # .env íŒŒì¼ ë¡œë“œ
DATABASE_URL = os.getenv("DATABASE_URL") # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ì½ê¸°
IMAGE_BASE_PATH = os.getenv("IMAGE_BASE_PATH", "/www/inday_fileinfo/img") # .envì—ì„œ ì½ê¸° (ì—†ì„ ê²½ìš° ê¸°ë³¸ê°’ ì‚¬ìš©)

if not DATABASE_URL:
    print("ğŸš¨ ì¹˜ëª…ì  ì—ëŸ¬: .env íŒŒì¼ì— DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! ì„œë²„ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # ì‹¤ì œ ìš´ì˜ ì‹œì—ëŠ” ì—¬ê¸°ì„œ ì—ëŸ¬ë¥¼ ë°œìƒì‹œí‚¤ê±°ë‚˜ ê¸°ë³¸ê°’ ì„¤ì • í•„ìš”
    raise ValueError("DATABASE_URL í™˜ê²½ ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") 

database = databases.Database(DATABASE_URL)
metadata = sqlalchemy.MetaData()

# 'homeprotection' í…Œì´ë¸” ì •ì˜
dogs_table = sqlalchemy.Table(
    "homeprotection",
    metadata,
    sqlalchemy.Column("uid", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("subject", sqlalchemy.String(250)),      # ìœ ê¸°ê²¬ ì´ë¦„
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),      # ì´ë¯¸ì§€ íŒŒì¼ (ê²½ë¡œ!)
    sqlalchemy.Column("addinfo03", sqlalchemy.String(10)),       # ì„±ë³„
    sqlalchemy.Column("addinfo04", sqlalchemy.String(10)),       # ì¤‘ì„±í™” ì—¬ë¶€
    sqlalchemy.Column("addinfo05", sqlalchemy.String(10)),       # ì¶œìƒ ì‹œê¸° (ë‚˜ì´)
    sqlalchemy.Column("addinfo07", sqlalchemy.String(10)),       # ëª¸ë¬´ê²Œ
    sqlalchemy.Column("addinfo08", sqlalchemy.Text),             # ì„±ê²© íƒœê·¸
    sqlalchemy.Column("addinfo09", sqlalchemy.Text),             # êµ¬ì¡° ì‚¬ì—°
    sqlalchemy.Column("addinfo10", sqlalchemy.Text),             # ì„±ê²© ë° íŠ¹ì§•
    sqlalchemy.Column("addinfo11", sqlalchemy.Text),             # ê¸°íƒ€ ì‚¬í•­
    sqlalchemy.Column("addinfo19", sqlalchemy.String(250)),      # ë³‘ë ¥ ì‚¬í•­
)

# --- 2. Pydantic ëª¨ë¸ ì •ì˜ ---
class Dog(BaseModel):
    uid: int
    subject: str
    s_pic01: str
    addinfo03: str | None
    addinfo04: str | None
    addinfo05: str | None
    addinfo07: str | None
    addinfo08: str | None
    addinfo09: str | None
    addinfo10: str | None
    addinfo11: str | None
    addinfo19: str | None

class RealProfileRequest(BaseModel):
    dog_uid: int

class ProfileResponse(BaseModel):
    profile_text: str
    profile_image_base64: str

# --- 3. FastAPI ì•± & AI ëª¨ë¸ ë³€ìˆ˜ ì„ ì–¸ ---
models = {}
app = FastAPI()

# --- 4. AI ëª¨ë¸ ë¡œë”© (ì„œë²„ ì‹œì‘ ì‹œ) ---
@app.on_event("startup")
def load_models_and_db():
    print("Cafe24 DB ì—°ê²° ì¤€ë¹„... (ê° API ìš”ì²­ ì‹œ ì—°ê²°)")

    print("AI ëª¨ë¸ ë¡œë”©ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ì‹œê°„ì´ ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")

    # (!!) Image-to-Image íŒŒì´í”„ë¼ì¸ ë¡œë“œ (SD 1.5 ê¸°ë°˜)
    print("Loading Stable Diffusion Image-to-Image pipeline...")
    # SDXL Image-to-ImageëŠ” ë‹¤ë¥¸ ëª¨ë¸ IDë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ (ë‚˜ì¤‘ì— ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤)
    models["image_pipe"] = StableDiffusionImg2ImgPipeline.from_pretrained(
        "runwayml/stable-diffusion-v1-5", # <-- ìš°ì„  SD 1.5 img2img ì‚¬ìš©
        torch_dtype=torch.float16,
    ).to(device)

    # (!!) 5.8B ëª¨ë¸ (GPU ë©”ëª¨ë¦¬ ìµœì í™”)
    print("Loading KoAlpaca-Polyglot-5.8B model...")
    models["tokenizer"] = AutoTokenizer.from_pretrained("beomi/KoAlpaca-Polyglot-5.8B")
    models["text_model"] = AutoModelForCausalLM.from_pretrained(
        "beomi/KoAlpaca-Polyglot-5.8B",
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True
    ).to(device)

    print("AI ëª¨ë¸ ë¡œë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# --- 5. DB ìë™ ì—°ê²°/í•´ì œ ì´ë²¤íŠ¸ ---
@app.on_event("shutdown")
async def shutdown_db_client():
    if database.is_connected:
        await database.disconnect()
        print("Cafe24 DB ì—°ê²°ì´ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

async def get_db_connection():
    if not database.is_connected:
        await database.connect()
    return database

# --- 6. í•µì‹¬ ê¸°ëŠ¥ API (DB ì—°ë™) ---
@app.get("/api/dogs", response_model=list[Dog])
async def get_dog_list(search: str | None = None):
    db = await get_db_connection()
    query = dogs_table.select()
    if search:
        query = query.where(
            (dogs_table.c.subject.ilike(f"%{search}%")) |
            (dogs_table.c.addinfo10.ilike(f"%{search}%"))
        )
    # Pydantic v1 í˜¸í™˜ì„±ì„ ìœ„í•´ RowProxyë¥¼ dictë¡œ ë³€í™˜ (FastAPI êµ¬ë²„ì „ ë“±ì—ì„œ í•„ìš”í•  ìˆ˜ ìˆìŒ)
    results = await db.fetch_all(query)
    return [dict(row) for row in results]


@app.get("/api/dogs/{dog_uid}", response_model=Dog)
async def get_dog_details(dog_uid: int):
    db = await get_db_connection()
    query = dogs_table.select().where(dogs_table.c.uid == dog_uid)
    dog = await db.fetch_one(query)
    if not dog:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ IDì˜ ê°•ì•„ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    # Pydantic v1 í˜¸í™˜ì„±ì„ ìœ„í•´ RowProxyë¥¼ dictë¡œ ë³€í™˜
    return dict(dog)


# --- 7. AI í”„ë¡œí•„ ìƒì„± API (Image-to-Image + ë³´ì•ˆ) ---
@app.post("/api/v1/generate-real-profile", response_model=ProfileResponse)
async def generate_real_profile(request: RealProfileRequest):
    if "image_pipe" not in models or "text_model" not in models:
        raise HTTPException(status_code=503, detail="AI ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    dog_dict = await get_dog_details(request.dog_uid)
    dog = Dog(**dog_dict) # Pydantic ëª¨ë¸ë¡œ ë³€í™˜

    # --- ì´ë¯¸ì§€ ì²˜ë¦¬ ---
    img_str = "Error processing image" # ê¸°ë³¸ê°’
    try:
        image_path = dog.s_pic01
# (!!) Cafe24 ì„œë²„ì˜ 'ì ˆëŒ€ íŒŒì¼ ê²½ë¡œ'ë¡œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ì—´ì–´ì•¼ í•¨.
        image_folder_path = IMAGE_BASE_PATH
        
        if not dog.s_pic01:
            raise ValueError("DBì— ì´ë¯¸ì§€ ê²½ë¡œ(s_pic01)ê°€ ì—†ìŠµë‹ˆë‹¤.")

        # os.path.joinì„ ì‚¬ìš©í•´ ì ˆëŒ€ ê²½ë¡œ ì¡°í•© (ì˜ˆ: /www/inday_fileinfo/img/filename.jpg)
        full_file_path = os.path.join(image_folder_path, dog.s_pic01)
        
        print(f"ì„œë²„ ë‚´ë¶€ ê²½ë¡œì—ì„œ ì´ë¯¸ì§€ ì—¬ëŠ” ì¤‘: {full_file_path}")
        
        if not os.path.exists(full_file_path):
            print(f"ê²½ê³ : íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤! {full_file_path}")
            raise HTTPException(status_code=404, detail=f"Image file not found at path: {full_file_path}")
            
        # HTTP ìš”ì²­ ëŒ€ì‹  íŒŒì¼ ì‹œìŠ¤í…œì—ì„œ ì§ì ‘ ì´ë¯¸ì§€ë¥¼ ì—´ê³ 
        input_image = Image.open(full_file_path).convert("RGB")

        print("ë°°ê²½ ì œê±° ì‹œì‘...")
        # (!!) alpha_matting=True ì˜µì…˜ ì¶”ê°€ (ì„ íƒì , ë” ë‚˜ì€ í’ˆì§ˆ ìœ„í•´)
        output_image = remove(input_image, alpha_matting=True) # RGBA
        print("ë°°ê²½ ì œê±° ì™„ë£Œ.")

        # Image-to-Image ì…ë ¥ ì¤€ë¹„ (ë°°ê²½ ì œê±°ëœ ì´ë¯¸ì§€ ì‚¬ìš©)
        output_image = output_image.resize((512, 512)) # SD 1.5 ê¸°ë³¸ í•´ìƒë„
        # RGBA -> RGB ë³€í™˜ (í°ìƒ‰ ë°°ê²½)
        rgb_image = Image.new("RGB", output_image.size, (255, 255, 255))
        rgb_image.paste(output_image, mask=output_image.split()[3])

        print("ì´ë¯¸ì§€ ê°œì„  ì‹œì‘...")
        prompt_image = f"high-quality professional studio photo of this cute dog named {dog.subject}, realistic, masterpiece, best quality, centered, plain light gray background" # ë°°ê²½ìƒ‰ ì§€ì •
        # strength ë‚®ì¶”ë©´ ì›ë³¸ ìœ ì§€ë ¥ ìƒìŠ¹, ë†’ì´ë©´ AI ì°½ì˜ì„± ì¦ê°€
        enhanced_image = models["image_pipe"](prompt=prompt_image, image=rgb_image, strength=0.6, guidance_scale=7.5).images[0]
        print("ì´ë¯¸ì§€ ê°œì„  ì™„ë£Œ.")

        buffered = BytesIO()
        enhanced_image.save(buffered, format="PNG")
        img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")

    except Exception as e:
        print(f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨ ì‹œì—ë„ í…ìŠ¤íŠ¸ëŠ” ìƒì„±í•˜ë„ë¡ ê³„ì† ì§„í–‰

    # --- í…ìŠ¤íŠ¸ ìƒì„± ---
    prompt_text = f"""
    # MISSION (ì„ë¬´)
    ë‹¹ì‹ ì€ êµ­ë‚´ ìµœê³ ì˜ ë™ë¬¼ êµ¬ì¡° ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ”, ì•„ë˜ [ê²¬ì¢… ì •ë³´]ë¥¼ ê°€ì§„ ìœ ê¸°ê²¬ì—ê²Œ 'í‰ìƒ ê°€ì¡±'ì„ ì°¾ì•„ì£¼ëŠ” ê²ƒì…ë‹ˆë‹¤.
    ì´ ì•„ì´ê°€ ì•„ë‹ˆë©´ ì•ˆ ë˜ê² ë‹¤ëŠ” 'ìš´ëª…ì ì¸ ëŒë¦¼'ì„ ëŠë¼ê²Œ ë§Œë“œëŠ”, ê°ì„±ì ì´ê³  ì„íŒ©íŠ¸ ìˆëŠ” í”„ë¡œí•„ì„ ì‘ì„±í•´ ì£¼ì„¸ìš”.

    # INSTRUCTIONS (ì‘ì„± ì§€ì¹¨)
    1.  **ë‚´ìš© ì¶©ì‹¤:** [ê²¬ì¢… ì •ë³´]ì— ìˆëŠ” ì‚¬ì‹¤ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    2.  **ë‹¨ì  ìŠ¹í™”:** ì•„ì´ì˜ ì•„í”ˆ 'ì‚¬ì—°'ì´ë‚˜ 'ë³‘ë ¥'ì€ 'ê·¹ë³µê³¼ í¬ë§'ìœ¼ë¡œ, 'íŠ¹ì§•'ì€ 'ë§¤ë ¥'ìœ¼ë¡œ ìŠ¹í™”ì‹œì¼œ ì£¼ì„¸ìš”.
    3.  **ê°ì„± ìê·¹:** ë…ìì˜ ë§ˆìŒì„ ì›€ì§ì´ê³ , ì´ ì•„ì´ì™€ í•¨ê»˜í•˜ëŠ” ë¯¸ë˜ë¥¼ ê·¸ë¦¬ê³  ì‹¶ë‹¤ëŠ” 'í•µì‹¬ ìš•êµ¬'ë¥¼ ìê·¹í•´ ì£¼ì„¸ìš”.
    4.  **ì–´ì¡°:** ë”°ëœ»í•˜ê³  ë‹¤ì •í•œ ê´€ì°°ì ì‹œì ìœ¼ë¡œ ì‘ì„±í•´ ì£¼ì„¸ìš”. (1ì¸ì¹­ X)

    # ê²¬ì¢… ì •ë³´ (Dog's Data)
    - ì´ë¦„: {dog.subject}
    - ì„±ë³„: {dog.addinfo03}
    - ë‚˜ì´(ì¶œìƒì‹œê¸°): {dog.addinfo05}
    - ëª¸ë¬´ê²Œ: {dog.addinfo07}kg
    - ì¤‘ì„±í™”: {dog.addinfo04}
    - ì„±ê²© íƒœê·¸: {dog.addinfo08}
    - ì„±ê²© ë° íŠ¹ì§•: {dog.addinfo10}
    - êµ¬ì¡° ì‚¬ì—°: {dog.addinfo09}
    - ë³‘ë ¥ ì‚¬í•­: {dog.addinfo19}
    - ê¸°íƒ€ ì‚¬í•­: {dog.addinfo11}
    ---
    # PROFILE (í”„ë¡œí•„ ì‘ì„±)
    ì†Œê°œê¸€:
    """

    generated_text = "Error generating text" # ê¸°ë³¸ê°’
    try:
        inputs = models["tokenizer"](prompt_text, return_tensors="pt").to(models["text_model"].device)
        output_sequences = models["text_model"].generate(
            input_ids=inputs['input_ids'],
            attention_mask=inputs['attention_mask'],
            max_new_tokens=300,
            temperature=0.7,
            repetition_penalty=1.2,
            # (!!) early_stopping=True ì¶”ê°€ (ìƒì„± ì™„ë£Œ ì‹œ ë¹ ë¥´ê²Œ ì¢…ë£Œ)
            early_stopping=True
        )
        # (!!) í…ìŠ¤íŠ¸ ê¹¨ì§ í•´ê²° ì‹œë„ (v6 ìœ ì§€)
        decoded_text = models["tokenizer"].decode(output_sequences[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)
        generated_text = decoded_text.split("ì†Œê°œê¸€:")[-1].strip()
        # (!!) ì¶”ê°€: ë§Œì•½ ê·¸ë˜ë„ ê¹¨ì§„ë‹¤ë©´ UTF-8 ê°•ì œ ì¸ì½”ë”©/ë””ì½”ë”© ì‹œë„ (í•˜ì§€ë§Œ ë³´í†µ decodeê°€ ì²˜ë¦¬í•¨)
        # generated_text = generated_text.encode('latin1').decode('utf-8', errors='ignore')
    except Exception as e:
        print(f"í…ìŠ¤íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


    return {
        "profile_text": generated_text,
        "profile_image_base64": img_str
    }
