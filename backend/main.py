import torchvision
try:
    import torchvision.transforms.functional_tensor
except ImportError:
    import torchvision.transforms.functional as F
    import sys
    sys.modules["torchvision.transforms.functional_tensor"] = F
# ---------------------------------------

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import torch
import numpy as np
import cv2
import io
import base64
import asyncio
import re
import textwrap
import requests
from typing import Optional, List, Tuple, Union, Dict
from PIL import Image, ImageDraw, ImageFont, ImageOps

import databases
import sqlalchemy
from rembg import new_session, remove 
from realesrgan import RealESRGANer 
from basicsr.archs.rrdbnet_arch import RRDBNet 
import openai 
import httpx 

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
IMAGE_BASE_PATH = os.getenv("IMAGE_BASE_PATH", "/inday_fileinfo/img")
SITE_BASE_URL = os.getenv("SITE_BASE_URL", "https://www.pimfyvirus.com")

database = databases.Database(DATABASE_URL) if DATABASE_URL else None
metadata = sqlalchemy.MetaData()

# --- DB í…Œì´ë¸” ì •ì˜ ---
dogs_table = sqlalchemy.Table(
    "homeprotection", metadata,
    sqlalchemy.Column("uid", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("subject", sqlalchemy.String(250)),
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),
    sqlalchemy.Column("addinfo01", sqlalchemy.String(100)), 
    sqlalchemy.Column("addinfo02", sqlalchemy.String(100)),
    sqlalchemy.Column("addinfo12", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo15", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo03", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo04", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo05", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo07", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo08", sqlalchemy.Text),
    sqlalchemy.Column("addinfo09", sqlalchemy.Text),
    sqlalchemy.Column("addinfo10", sqlalchemy.Text),
    sqlalchemy.Column("addinfo11", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo19", sqlalchemy.String(250)),
)

sub02_table = sqlalchemy.Table(
    "homeprotectionsub02", metadata,
    sqlalchemy.Column("puid", sqlalchemy.Integer), 
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),
    sqlalchemy.Column("num", sqlalchemy.Integer), 
)

# --- ë°ì´í„° ëª¨ë¸ ---
class Dog(BaseModel):
    uid: int
    subject: str
    s_pic01: Optional[str] = None
    image_filenames: List[str] = [] 
    addinfo01: Optional[str] = None 
    addinfo02: Optional[str] = None 
    addinfo03: Optional[str] = None
    addinfo04: Optional[str] = None
    addinfo05: Optional[str] = None
    addinfo07: Optional[str] = None
    addinfo08: Optional[str] = None
    addinfo09: Optional[str] = None
    addinfo10: Optional[str] = None
    addinfo11: Optional[str] = None
    addinfo12: Optional[str] = None
    addinfo15: Optional[str] = None
    addinfo19: Optional[str] = None

class RealProfileRequest(BaseModel):
    dog_uid: int

# --- ì•± ì´ˆê¸°í™” ---
models = {}
app = FastAPI()

if torch.cuda.is_available():
    device = "cuda"
    gpu_id = 0
    print(f"ğŸš€ [System] GPU ëª¨ë“œ í™œì„±í™”: {torch.cuda.get_device_name(0)}")
else:
    device = "cpu"
    gpu_id = None
    print("âš ï¸ [System] ê²½ê³ : GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

SDXL_SERVICE_URL = "http://sdxl-service:8001/generate/background"

@app.on_event("startup")
def load_models_and_db():
    print("ğŸš€ AI ì„œë²„ ì‹œì‘: ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # 1. Real-ESRGAN
    print("Loading Real-ESRGAN PyTorch Model...")
    try:
        model_arch = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
        model_path = "/app/esrgan/RealESRGAN_x4plus.pth"
        models["upsampler"] = RealESRGANer(
            scale=4, model_path=model_path, model=model_arch, tile=0, tile_pad=10, pre_pad=0,
            half=True if device == "cuda" else False, gpu_id=gpu_id
        )
        print("âœ… Real-ESRGAN Loaded.")
    except Exception as e:
        print(f"ğŸš¨ Real-ESRGAN Failed: {e}")

    # 2. Rembg (ì„ ë³„ìš©)
    print("Loading Rembg for Selection...")
    try:
        models["remover"] = new_session(model_name="isnet-general-use")
        print("âœ… Rembg Loaded.")
    except:
        models["remover"] = new_session()

    print("--- ëª¨ë“  AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ ---")

@app.on_event("shutdown")
async def shutdown_db_client():
    if database and database.is_connected: await database.disconnect()

async def get_db_connection():
    if database and not database.is_connected: await database.connect()
    return database

# --- Helper Functions ---
async def get_dog_details(dog_uid: int) -> Dog:
    db = await get_db_connection()
    if not db: raise HTTPException(status_code=500, detail="DB Fail")
    main_query = dogs_table.select().where(dogs_table.c.uid == dog_uid)
    dog_data = await db.fetch_one(main_query)
    if not dog_data: raise HTTPException(status_code=404, detail="Dog Not Found")
    image_query = sub02_table.select().where(sub02_table.c.puid == dog_uid).order_by(sub02_table.c.num)
    image_data_list = await db.fetch_all(image_query)
    image_filenames = [row['s_pic01'] for row in image_data_list]
    return Dog(**dog_data, image_filenames=image_filenames)

def pil_to_cv2(pil_image):
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

def cv2_to_pil(cv2_image):
    return Image.fromarray(cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB))

def draw_text_with_stroke(draw, x, y, text, font, fill_color, stroke_color, stroke_width):
    for dx, dy in [(sx, sy) for sx in range(-stroke_width, stroke_width + 1) for sy in range(-stroke_width, stroke_width + 1) if sx * sx + sy * sy <= stroke_width * stroke_width]:
        draw.text((x + dx, y + dy), text, font=font, fill=stroke_color)
    draw.text((x, y), text, font=font, fill=fill_color)

def get_text_width(draw, text, font):
    try: return draw.textlength(text, font=font)
    except: return len(text) * (font.size * 0.6)

def remove_emojis(text):
    if not text: return ""
    return re.sub(r'[^\w\s,.\-?!@#%&()ê°€-í£/]', '', text).strip()

async def call_sdxl_service(base64_dog_image: str, dog_info: dict) -> Image.Image:
    color_hint = "warm cream and white"
    prompt_detail = "A minimalist aesthetic background, warm sunlight shadows on a white wall, clean interior, cozy atmosphere, high quality, soft focus, instagram vibe."

    payload = {"base64_dog_image": base64_dog_image, "prompt": prompt_detail, "color_hint": color_hint}
    print(f"Calling SDXL... Hint: {color_hint}")
    
    async with httpx.AsyncClient(timeout=100.0) as client:
        try:
            response = await client.post(SDXL_SERVICE_URL, json=payload)
            response.raise_for_status()  
            result = response.json()
            base64_bg = result.get("base64_background_image")
            if not base64_bg: raise ValueError("No bg image")
            return Image.open(io.BytesIO(base64.b64decode(base64_bg))).convert("RGB")
        except Exception as e:
            print(f"ğŸš¨ SDXL Error: {e}")
            return Image.new('RGB', (1080, 1350), (250, 245, 240)) 

def generate_dog_text(dog: Dog) -> Dict: 
    def clean_text(text):
        if not text: return ""
        text = re.sub(r'<[^>]+>', '', text)
        return remove_emojis(text)

    raw_name = dog.subject.split('/')[0] if '/' in dog.subject else dog.subject
    dog_name_only = clean_text(raw_name).strip()
    display_age = dog.addinfo05 if dog.addinfo05 and not dog.addinfo05.isdigit() else "ì •ë³´ ì—†ìŒ"
    
    basic_info_lines = [
        f"ì´ë¦„: {dog_name_only}",
        f"ì„±ë³„: {clean_text(dog.addinfo03)}",
        f"ì¶œìƒì‹œê¸°: {display_age}", 
        f"ëª¸ë¬´ê²Œ: {clean_text(dog.addinfo07)}kg",
        f"ì¤‘ì„±í™”: {clean_text(dog.addinfo04)}",
    ]
    
    # ì—°ë½ì²˜ ì •ë³´ ì œì™¸
    info_source = [dog.addinfo08, dog.addinfo09, dog.addinfo10, dog.addinfo01]
    story_data = f"ì´ë¦„:{dog_name_only}, " + " ".join([clean_text(x) for x in info_source if x])
    
    # â­ï¸ [ìˆ˜ì •ë¨] 1ì¸ì¹­ ì¡´ëŒ“ë§ & ê°ì„± ë§íˆ¬ ê°•ì œ í”„ë¡¬í”„íŠ¸
    system_prompt = """
    ë‹¹ì‹ ì€ ì…ì–‘ì„ ê¸°ë‹¤ë¦¬ëŠ” ìœ ê¸°ê²¬ì…ë‹ˆë‹¤. ë¯¸ë˜ì˜ ê°€ì¡±ì—ê²Œ ë³´ë‚´ëŠ” ì§§ì€ í¸ì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
    ë‹¤ìŒ ê·œì¹™ì„ ë°˜ë“œì‹œ ì§€í‚¤ì„¸ìš”:
    1. ì‹œì : ë¬´ì¡°ê±´ 'ì €', 'ì œ'ë¥¼ ì‚¬ìš©í•œ 1ì¸ì¹­ ì‹œì . (ì˜ˆ: "ì €ëŠ” ë°¤ì´ì—ìš”!")
    2. ë§íˆ¬: ì˜ˆì˜ ë°”ë¥´ê³  ë‹¤ì •í•˜ë©° ì‚¬ë‘ìŠ¤ëŸ¬ìš´ 'ì¡´ëŒ“ë§(í•´ìš”ì²´)'ì„ ì‚¬ìš©í•˜ì„¸ìš”.
    3. ê¸ˆì§€ì‚¬í•­: 'ì´ ì¹œêµ¬ëŠ”', 'ì†Œë‹´ì´ëŠ”' ì²˜ëŸ¼ ì œ3ìê°€ ì„¤ëª…í•˜ëŠ” ë§íˆ¬ ì ˆëŒ€ ê¸ˆì§€. 'ë‚¨ì„±ë¶„ë“¤ì€~' ê°™ì€ ë³µì¡í•œ ì¡°ê±´ì´ë‚˜ ë¶€ì •ì ì¸ ë‚´ìš© ê¸ˆì§€.
    4. ë‚´ìš©: ê°•ì•„ì§€ì˜ ì„±ê²©ê³¼ ë§¤ë ¥ì„ ì–´í•„í•˜ê³ , ê°€ì¡±ì„ ë§Œë‚˜ê³  ì‹¶ë‹¤ëŠ” ì†Œë§ì„ 2~3ë¬¸ì¥ìœ¼ë¡œ í‘œí˜„í•˜ì„¸ìš”.
    5. ì˜ˆì‹œ: "ì•ˆë…•í•˜ì„¸ìš”, ì „ ë°¤ì´ë¼ê³  í•´ìš”! ì „ ì‚°ì±…ì„ ì¢‹ì•„í•˜ê³  ì‚¬ëŒ í’ˆì„ ë„ˆë¬´ ì¢‹ì•„í•´ìš”. í‰ìƒ ê°€ì¡±ê³¼ í•¨ê»˜ í–‰ë³µí•˜ê²Œ ì‚¬ëŠ” ê²Œ ì œ ê¿ˆì´ì—ìš”!"
    """
    
    messages = [
        {"role": "system", "content": system_prompt},
        {"role": "user", "content": f"ê°•ì•„ì§€ ì •ë³´: {story_data}"}
    ]
    
    generated_story = ""
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        res = client.chat.completions.create(model="gpt-4o-mini", messages=messages, max_tokens=300)
        generated_story = remove_emojis(res.choices[0].message.content.strip())
    except Exception as e:
        print(f"ğŸš¨ OpenAI Error: {e}")
        generated_story = f"ì•ˆë…•í•˜ì„¸ìš”, ì €ëŠ” {dog_name_only}ì˜ˆìš”! ì €ì˜ í‰ìƒ ê°€ì¡±ì´ ë˜ì–´ì£¼ì‹¤ ë¶„ì„ ê¸°ë‹¤ë¦¬ê³  ìˆì–´ìš”."

    return {
        "basic_info": basic_info_lines,
        "story": generated_story,
        "name": dog_name_only
    }

# â­ï¸ ì‚¬ì§„ ì„ ë³„ ë¡œì§ (íšŒì „ ë³´ì • ì¶”ê°€)
async def select_best_image(dog: Dog) -> Union[Image.Image, None]:
    best_img, best_score = None, -9999
    imgs = list(dict.fromkeys([x for x in ([dog.s_pic01] + dog.image_filenames) if x and x.strip()]))
    if not imgs: return None
    
    remover = models.get("remover")
    if not remover: return None 

    print(f"[{dog.uid}] AI ìŠ¤ë§ˆíŠ¸ ì„ ë³„ ì¤‘ ({len(imgs)}ì¥)...")
    
    for fname in imgs:
        try:
            url = f"{SITE_BASE_URL}{IMAGE_BASE_PATH}/{fname}"
            res = requests.get(url, stream=True, timeout=5)
            res.raise_for_status()
            img = Image.open(res.raw).convert("RGB")
            
            # â­ï¸ [ì¶”ê°€ë¨] EXIF ì •ë³´ì— ë”°ë¼ ì´ë¯¸ì§€ íšŒì „ ë³´ì • (ë‘ë¶€ ì‚¬ì§„ ëˆ•ëŠ” í˜„ìƒ í•´ê²°)
            img = ImageOps.exif_transpose(img)
            
            w, h = img.size
            if w < 250 or h < 250: continue 

            # í‰ê°€ìš© ë¦¬ì‚¬ì´ì§•
            small_w = 320
            small_h = int(h * (small_w / w))
            img_small = img.resize((small_w, small_h))
            
            # rembg ì‹¤í–‰
            no_bg = remove(img_small, session=remover, alpha_matting=False)
            
            alpha = np.array(no_bg.split()[3])
            if cv2.countNonZero(alpha) == 0: continue 
            
            coords = cv2.findNonZero(alpha)
            x, y, box_w, box_h = cv2.boundingRect(coords)
            
            # ì ìˆ˜ ì‚°ì •
            mask_area = box_w * box_h
            total_area = small_w * small_h
            score_size = (mask_area / total_area) * 100 

            center_x = x + box_w / 2
            center_y = y + box_h / 2
            dist_from_center = ((center_x - small_w/2)**2 + (center_y - small_h/2)**2)**0.5
            max_dist = (small_w**2 + small_h**2)**0.5
            score_center = (1 - (dist_from_center / max_dist)) * 50 
            
            img_gray = cv2.cvtColor(np.array(img_small), cv2.COLOR_RGB2GRAY)
            masked_gray = img_gray[y:y+box_h, x:x+box_w]
            if masked_gray.size > 0:
                laplacian_var = cv2.Laplacian(masked_gray, cv2.CV_64F).var()
                score_sharp = min(laplacian_var, 500) / 10 
            else:
                score_sharp = 0
                
            score_penalty = 0
            if h > w * 2.2: score_penalty = 30 
            
            total_score = score_size + score_center + score_sharp - score_penalty
            if h > w: total_score += 20
            
            if total_score > best_score:
                best_score = total_score
                best_img = img
                
        except Exception as e:
            continue
            
    return best_img

# --- ë©”ì¸ API ---
@app.post("/api/v1/generate-real-profile", response_model=dict)
async def generate_real_profile(request: RealProfileRequest):
    if "upsampler" not in models: raise HTTPException(status_code=503, detail="Model Loading")
    dog = await get_dog_details(request.dog_uid)
    
    best_img = await select_best_image(dog)
    if not best_img: return {"profile_text": "ì´ë¯¸ì§€ ì—†ìŒ", "profile_image_base64": ""}
    
    # ì›ë³¸ ë³´ì¡´
    buf_orig = io.BytesIO()
    best_img.save(buf_orig, format="JPEG")
    orig_b64 = base64.b64encode(buf_orig.getvalue()).decode("utf-8")

    try:
        # 1. í™”ì§ˆ ê°œì„ 
        cv2_img = pil_to_cv2(best_img)
        output, _ = models["upsampler"].enhance(cv2_img, outscale=4)
        upscaled_pil = cv2_to_pil(output)
        print("âœ… í™”ì§ˆ ë³µì› ì™„ë£Œ")

        # 2. ì•¡ì ìŠ¤íƒ€ì¼
        w, h = upscaled_pil.size
        min_dim = min(w, h)
        left, top = (w - min_dim)/2, (h - min_dim)/2
        crop_img = upscaled_pil.crop((left, top, left + min_dim, top + min_dim))
        
        border_size = int(min_dim * 0.05)
        processed_img = ImageOps.expand(crop_img, border=border_size, fill='white')
        
        # 3. ë°°ê²½ ìƒì„±
        buf = io.BytesIO()
        processed_img.save(buf, format="PNG") 
        b64_png = base64.b64encode(buf.getvalue()).decode("utf-8")
        bg_img = await call_sdxl_service(b64_png, {"name": dog.subject})
        
        # 4. í…ìŠ¤íŠ¸ ë° ë ˆì´ì•„ì›ƒ
        text_data = generate_dog_text(dog)
        
        template_w, template_h = 1080, 1350
        template = bg_img.resize((template_w, template_h))
        draw = ImageDraw.Draw(template)
        
        try:
            ft = ImageFont.truetype("/app/KyoboHandwriting2021sjy.otf", 80)
            fb = ImageFont.truetype("/app/KyoboHandwriting2021sjy.otf", 38)
        except: 
            ft = fb = ImageFont.load_default()

        # íƒ€ì´í‹€
        t_txt = f"{text_data['name']}ì˜ ê°€ì¡±ì„ ì°¾ìŠµë‹ˆë‹¤."
        tw = get_text_width(draw, t_txt, ft)
        draw_text_with_stroke(draw, (template_w-tw)/2, 60, t_txt, ft, (255,255,255), (0,0,0), 3)
        header_height = 180

        lines = text_data['basic_info'] + textwrap.wrap(text_data['story'], width=35)
        line_height = 50
        text_total_height = (len(lines) * line_height) + 50 
        footer_margin = 100 
        
        available_h = template_h - header_height - text_total_height - footer_margin
        
        p_w, p_h = processed_img.size
        target_w = 900
        target_h = int(p_h * (target_w / p_w))
        
        if target_h > available_h:
            target_h = available_h
            target_w = int(p_w * (target_h / p_h))

        paste_img = processed_img.resize((target_w, target_h))
        template.paste(paste_img, ((template_w-target_w)//2, header_height))
        
        cy = header_height + target_h + 40
        for line in lines:
            w = get_text_width(draw, line, fb)
            draw_text_with_stroke(draw, (template_w-w)/2, cy, line, fb, (50,50,50), (255,255,255), 2)
            cy += line_height
        
        # 5. JPEG ì €ì¥
        buf = io.BytesIO()
        template = template.convert("RGB")
        template.save(buf, format="JPEG", quality=90, optimize=True)
        final_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        
        return {
            "profile_text": '\n'.join(text_data['basic_info'] + [text_data['story']]), 
            "profile_image_base64": final_b64
        }
        
    except Exception as e:
        print(f"ğŸš¨ Processing Error: {e}")
        return {"profile_text": "Error", "profile_image_base64": orig_b64}
