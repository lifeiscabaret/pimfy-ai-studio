from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import torch
from diffusers import AutoPipelineForText2Image
from transformers import AutoTokenizer, AutoModelForCausalLM
import base64
from io import BytesIO
import asyncio
import databases
import sqlalchemy

# --- 1. Cafe24 DB (MySQL) ì„¤ì • ---
load_dotenv() # <-- .env íŒŒì¼ ë¡œë“œí•˜ëŠ” ì½”ë“œ ì¶”ê°€
DATABASE_URL = os.getenv("DATABASE_URL")

# (!!) DATABASE_URLì´ ì œëŒ€ë¡œ ë¡œë“œë˜ì—ˆëŠ”ì§€ í™•ì¸ (ì„ íƒ ì‚¬í•­)
if not DATABASE_URL:
    print("ðŸš¨ ì—ëŸ¬: .env íŒŒì¼ì— DATABASE_URLì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
    # ë˜ëŠ” raise Exception(...) ë“±ìœ¼ë¡œ ì—ëŸ¬ ì²˜ë¦¬

database = databases.Database(DATABASE_URL)
metadata = sqlalchemy.MetaData()

# (!!) 'ì§„ì§œ' ìœ ê¸°ê²¬ ê³µê³  í…Œì´ë¸” 'homeprotection'
dogs_table = sqlalchemy.Table(
    "homeprotection",
    metadata,
    sqlalchemy.Column("uid", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("subject", sqlalchemy.String(250)),      # ìœ ê¸°ê²¬ ì´ë¦„
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),      # ì´ë¯¸ì§€ íŒŒì¼
    sqlalchemy.Column("addinfo03", sqlalchemy.String(10)),       # ì„±ë³„
    sqlalchemy.Column("addinfo04", sqlalchemy.String(10)),       # (!!) ì¤‘ì„±í™” ì—¬ë¶€
    sqlalchemy.Column("addinfo05", sqlalchemy.String(10)),       # ì¶œìƒ ì‹œê¸° (ë‚˜ì´)
    sqlalchemy.Column("addinfo07", sqlalchemy.String(10)),       # (!!) ëª¸ë¬´ê²Œ
    sqlalchemy.Column("addinfo08", sqlalchemy.Text),             # (!!) ì„±ê²© íƒœê·¸
    sqlalchemy.Column("addinfo09", sqlalchemy.Text),             # êµ¬ì¡° ì‚¬ì—°
    sqlalchemy.Column("addinfo10", sqlalchemy.Text),             # ì„±ê²© ë° íŠ¹ì§•
    sqlalchemy.Column("addinfo11", sqlalchemy.Text),             # (!!) ê¸°íƒ€ ì‚¬í•­
    sqlalchemy.Column("addinfo19", sqlalchemy.String(250)),      # (!!) ë³‘ë ¥ ì‚¬í•­
)

# --- 2. Pydantic ëª¨ë¸ ì •ì˜ (API ìž…ì¶œë ¥ í˜•ì‹) ---
class Dog(BaseModel):
    uid: int
    subject: str
    s_pic01: str
    addinfo03: str | None
    addinfo04: str | None
    addinfo05: str | None
    addinfo07: str | None
    addinfo08: str | None
    addinfo09: str | None
    addinfo10: str | None
    addinfo11: str | None
    addinfo19: str | None

class RealProfileRequest(BaseModel):
    dog_uid: int

class ProfileResponse(BaseModel):
    profile_text: str
    profile_image_base64: str

# --- 3. (!!) FastAPI ì•± & AI ëª¨ë¸ ë³€ìˆ˜ ì„ ì–¸ ---
models = {} 
app = FastAPI() # (!!) 'app'ì„ ì—¬ê¸°ì„œ ë¨¼ì € ì •ì˜í•©ë‹ˆë‹¤.

# --- 4. 'ì§„ì§œ' AI ëª¨ë¸ ë¡œë”© (ì„œë²„ ì‹œìž‘ ì‹œ) ---
@app.on_event("startup")
def load_models_and_db():
    print("Cafe24 DB ì—°ê²° ì¤€ë¹„... (ê° API ìš”ì²­ ì‹œ ì—°ê²°)")

    print("AI ëª¨ë¸ ë¡œë”©ì„ ì‹œìž‘í•©ë‹ˆë‹¤... (ì‹œê°„ì´ ëª‡ ë¶„ ì •ë„ ê±¸ë¦´ ìˆ˜ ìžˆìŠµë‹ˆë‹¤)")
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"Using device: {device}")
    
    models["image_pipe"] = AutoPipelineForText2Image.from_pretrained(
        "stabilityai/stable-diffusion-xl-base-1.0",
        torch_dtype=torch.float16,
        variant="fp16"
    ).to(device)
    
    models["tokenizer"] = AutoTokenizer.from_pretrained("beomi/KoAlpaca-Polyglot-5.8B")
    models["text_model"] = AutoModelForCausalLM.from_pretrained(
    "beomi/KoAlpaca-Polyglot-5.8B", # <--- ì´ ë¶€ë¶„!
    torch_dtype=torch.float16,
    low_cpu_mem_usage=True
).to(device)
    
    print("AI ëª¨ë¸ ë¡œë”©ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")


# --- 5. DB ìžë™ ì—°ê²°/í•´ì œ ì´ë²¤íŠ¸ ---
@app.on_event("shutdown")
async def shutdown_db_client():
    if database.is_connected:
        await database.disconnect()
        print("Cafe24 DB ì—°ê²°ì´ í•´ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

async def get_db_connection():
    if not database.is_connected:
        await database.connect()
    return database

# --- 6. í•µì‹¬ ê¸°ëŠ¥ API (DB ì—°ë™) ---
@app.get("/api/dogs", response_model=list[Dog])
async def get_dog_list(search: str | None = None):
    db = await get_db_connection()
    query = dogs_table.select()
    if search:
        query = query.where(
            (dogs_table.c.subject.ilike(f"%{search}%")) |
            (dogs_table.c.addinfo10.ilike(f"%{search}%"))
        )
    return await db.fetch_all(query)

@app.get("/api/dogs/{dog_uid}", response_model=Dog)
async def get_dog_details(dog_uid: int):
    db = await get_db_connection()
    query = dogs_table.select().where(dogs_table.c.uid == dog_uid)
    dog = await db.fetch_one(query)
    if not dog:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ IDì˜ ê°•ì•„ì§€ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return dog


# --- 7. AI í”„ë¡œí•„ ìƒì„± API ---
@app.post("/api/v1/generate-real-profile", response_model=ProfileResponse)
async def generate_real_profile(request: RealProfileRequest):
    if "image_pipe" not in models or "text_model" not in models:
        raise HTTPException(status_code=503, detail="AI ëª¨ë¸ì´ ì•„ì§ ë¡œë“œë˜ì§€ ì•Šì•˜ê±°ë‚˜ ì¤€ë¹„ ì¤‘ìž…ë‹ˆë‹¤. ìž ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")

    dog = await get_dog_details(request.dog_uid)

    prompt_text = f"""
    # MISSION (ìž„ë¬´)
    ë‹¹ì‹ ì€ êµ­ë‚´ ìµœê³ ì˜ ë™ë¬¼ êµ¬ì¡° ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ìž…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìœ ì¼í•œ ìž„ë¬´ëŠ”, ì•„ëž˜ [ê²¬ì¢… ì •ë³´]ë¥¼ ê°€ì§„ ìœ ê¸°ê²¬ì—ê²Œ 'í‰ìƒ ê°€ì¡±'ì„ ì°¾ì•„ì£¼ëŠ” ê²ƒìž…ë‹ˆë‹¤.
    ì´ ì•„ì´ê°€ ì•„ë‹ˆë©´ ì•ˆ ë˜ê² ë‹¤ëŠ” 'ìš´ëª…ì ì¸ ëŒë¦¼'ì„ ëŠë¼ê²Œ ë§Œë“œëŠ”, ê°ì„±ì ì´ê³  ìž„íŒ©íŠ¸ ìžˆëŠ” í”„ë¡œí•„ì„ ìž‘ì„±í•´ ì£¼ì„¸ìš”.

    # INSTRUCTIONS (ìž‘ì„± ì§€ì¹¨)
    1.  **ë‚´ìš© ì¶©ì‹¤:** [ê²¬ì¢… ì •ë³´]ì— ìžˆëŠ” ì‚¬ì‹¤ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ìž‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.
    2.  **ë‹¨ì  ìŠ¹í™”:** ì•„ì´ì˜ ì•„í”ˆ 'ì‚¬ì—°'ì´ë‚˜ 'ë³‘ë ¥'ì€ 'ê·¹ë³µê³¼ í¬ë§'ìœ¼ë¡œ, 'íŠ¹ì§•'ì€ 'ë§¤ë ¥'ìœ¼ë¡œ ìŠ¹í™”ì‹œì¼œ ì£¼ì„¸ìš”.
    3.  **ê°ì„± ìžê·¹:** ë…ìžì˜ ë§ˆìŒì„ ì›€ì§ì´ê³ , ì´ ì•„ì´ì™€ í•¨ê»˜í•˜ëŠ” ë¯¸ëž˜ë¥¼ ê·¸ë¦¬ê³  ì‹¶ë‹¤ëŠ” 'í•µì‹¬ ìš•êµ¬'ë¥¼ ìžê·¹í•´ ì£¼ì„¸ìš”.
    4.  **ì–´ì¡°:** ë”°ëœ»í•˜ê³  ë‹¤ì •í•œ ê´€ì°°ìž ì‹œì ìœ¼ë¡œ ìž‘ì„±í•´ ì£¼ì„¸ìš”. (1ì¸ì¹­ X)

    # ê²¬ì¢… ì •ë³´ (Dog's Data)
    - ì´ë¦„: {dog.subject}
    - ì„±ë³„: {dog.addinfo03}
    - ë‚˜ì´(ì¶œìƒì‹œê¸°): {dog.addinfo05}
    - ëª¸ë¬´ê²Œ: {dog.addinfo07}kg
    - ì¤‘ì„±í™”: {dog.addinfo04}
    - ì„±ê²© íƒœê·¸: {dog.addinfo08}
    - ì„±ê²© ë° íŠ¹ì§•: {dog.addinfo10}
    - êµ¬ì¡° ì‚¬ì—°: {dog.addinfo09}
    - ë³‘ë ¥ ì‚¬í•­: {dog.addinfo19}
    - ê¸°íƒ€ ì‚¬í•­: {dog.addinfo11}
    ---
    # PROFILE (í”„ë¡œí•„ ìž‘ì„±)
    ì†Œê°œê¸€:
    """
    
    inputs = models["tokenizer"](prompt_text, return_tensors="pt").to(models["text_model"].device)
    
    # (!!) (!!) (!!) ì—ëŸ¬ ìˆ˜ì •! (v4)
    # Ko-Alpaca (GPT-NeoX) ëª¨ë¸ì€ 'token_type_ids'ë¥¼ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë° ë„£ì–´ì„œ ì¶©ëŒë°œìƒ.
    # inputs ëŒ€ì‹ , í•„ìš”í•œ 'input_ids'ì™€ 'attention_mask'ë§Œ ëª…ì‹œì ìœ¼ë¡œ ì „ë‹¬í•©ë‹ˆë‹¤.
    output_sequences = models["text_model"].generate(
        input_ids=inputs['input_ids'], 
        attention_mask=inputs['attention_mask'], 
        max_new_tokens=300, 
        temperature=0.7, 
        repetition_penalty=1.2
    )
    
    generated_text = models["tokenizer"].decode(output_sequences[0], skip_special_tokens=True)
    
    prompt_image = f"A high-resolution, heartwarming studio photo of a cute dog named {dog.subject}, looking at the camera"
    image = models["image_pipe"](prompt=prompt_image).images[0]
    
    buffered = BytesIO()
    image.save(buffered, format="PNG")
    img_str = base64.b64encode(buffered.getvalue()).decode("utf-8")

    return {
        "profile_text": generated_text.split("ì†Œê°œê¸€:")[-1].strip(),
        "profile_image_base64": img_str
    }