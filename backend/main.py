import torchvision
try:
    # torchvision 0.17+ ë²„ì „ì—ì„œ ì‚­ì œëœ functional_tensorë¥¼ functionalë¡œ ìš°íšŒ ì—°ê²°
    import torchvision.transforms.functional_tensor
except ImportError:
    import torchvision.transforms.functional as F
    import sys
    sys.modules["torchvision.transforms.functional_tensor"] = F
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import os
from dotenv import load_dotenv
import torch
import numpy as np
import cv2
import io
import base64
import asyncio
import re
import textwrap
import requests
from typing import Optional, List, Tuple, Union

# --- [í•„ìˆ˜] PyTorch ëª¨ë¸ ë¡œë”© ë³´ì•ˆ íŒ¨ì¹˜ ---
_original_load = torch.load
def _safe_load(*args, **kwargs):
    if 'weights_only' not in kwargs:
        kwargs['weights_only'] = False
    return _original_load(*args, **kwargs)
torch.load = _safe_load
# ---------------------------------------

import databases
import sqlalchemy
from rembg import new_session, remove
from realesrgan import RealESRGANer 
from basicsr.archs.rrdbnet_arch import RRDBNet 
from PIL import Image, ImageDraw, ImageFont, ImageFilter
import openai 
import httpx 

load_dotenv()
DATABASE_URL = os.getenv("DATABASE_URL")
IMAGE_BASE_PATH = os.getenv("IMAGE_BASE_PATH", "/inday_fileinfo/img")
SITE_BASE_URL = os.getenv("SITE_BASE_URL", "https://www.pimfyvirus.com")

database = databases.Database(DATABASE_URL) if DATABASE_URL else None
metadata = sqlalchemy.MetaData()

# --- DB í…Œì´ë¸” ì •ì˜ ---
dogs_table = sqlalchemy.Table(
    "homeprotection", metadata,
    sqlalchemy.Column("uid", sqlalchemy.Integer, primary_key=True),
    sqlalchemy.Column("subject", sqlalchemy.String(250)),
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),
    sqlalchemy.Column("addinfo01", sqlalchemy.String(100)), 
    sqlalchemy.Column("addinfo02", sqlalchemy.String(100)),
    sqlalchemy.Column("addinfo12", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo15", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo03", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo04", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo05", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo07", sqlalchemy.String(10)),
    sqlalchemy.Column("addinfo08", sqlalchemy.Text),
    sqlalchemy.Column("addinfo09", sqlalchemy.Text),
    sqlalchemy.Column("addinfo10", sqlalchemy.Text),
    sqlalchemy.Column("addinfo11", sqlalchemy.String(250)),
    sqlalchemy.Column("addinfo19", sqlalchemy.String(250)),
)

sub02_table = sqlalchemy.Table(
    "homeprotectionsub02", metadata,
    sqlalchemy.Column("puid", sqlalchemy.Integer), 
    sqlalchemy.Column("s_pic01", sqlalchemy.String(150)),
    sqlalchemy.Column("num", sqlalchemy.Integer), 
)

# --- ë°ì´í„° ëª¨ë¸ ---
class Dog(BaseModel):
    uid: int
    subject: str
    s_pic01: Optional[str] = None
    image_filenames: List[str] = [] 
    addinfo03: Optional[str] = None
    addinfo04: Optional[str] = None
    addinfo05: Optional[str] = None
    addinfo07: Optional[str] = None
    addinfo08: Optional[str] = None
    addinfo09: Optional[str] = None
    addinfo10: Optional[str] = None
    addinfo11: Optional[str] = None
    addinfo19: Optional[str] = None

class RealProfileRequest(BaseModel):
    dog_uid: int

# --- ì•± ì´ˆê¸°í™” ---
models = {}
app = FastAPI()

# â­ï¸ GPU ëª¨ë“œ í™•ì¸ ë° ì„¤ì •
if torch.cuda.is_available():
    device = "cuda"
    gpu_id = 0
    print(f"ğŸš€ [System] GPU ëª¨ë“œ í™œì„±í™”: {torch.cuda.get_device_name(0)}")
else:
    device = "cpu"
    gpu_id = None
    print("âš ï¸ [System] ê²½ê³ : GPUë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. CPUë¡œ ì‹¤í–‰ë©ë‹ˆë‹¤.")

SDXL_SERVICE_URL = "http://sdxl-service:8001/generate/background"

@app.on_event("startup")
def load_models_and_db():
    print("ğŸš€ AI ì„œë²„ ì‹œì‘: ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    # (1) Real-ESRGAN ë¡œë“œ
    print("Loading Real-ESRGAN PyTorch Model...")
    try:
        model_arch = RRDBNet(num_in_ch=3, num_out_ch=3, num_feat=64, num_block=23, num_grow_ch=32, scale=4)
        model_path = "/app/esrgan/RealESRGAN_x4plus.pth"

        models["upsampler"] = RealESRGANer(
            scale=4,
            model_path=model_path,
            model=model_arch,
            tile=0,       #ï¸ V100 í’€íŒŒì›Œ
            tile_pad=10,
            pre_pad=0,
            half=True if device == "cuda" else False, 
            gpu_id=gpu_id
        )
        print("âœ… Real-ESRGAN PyTorch Model loaded successfully.")
    except Exception as e:
        print(f"ğŸš¨ Real-ESRGAN Load Failed: {e}")

    # (2) rembg ë¡œë“œ (BiRefNet ì ìš©)
    print("Loading rembg session (BiRefNet)...")
    try:
        # í„¸ ë¬˜ì‚¬ ì—…ê·¸ë ˆì´ë“œ ëª¨ë¸ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œ ì‹œê°„ ì†Œìš”)
        models["remover"] = new_session(model_name="birefnet-general")
        print("âœ… rembg ì„¸ì…˜ ë¡œë“œ ì™„ë£Œ (Model: birefnet-general).")
    except Exception as e:
        print(f"ğŸš¨ BiRefNet ë¡œë“œ ì‹¤íŒ¨: {e}. ê¸°ì¡´ isnetìœ¼ë¡œ í´ë°±í•©ë‹ˆë‹¤.")
        models["remover"] = new_session(model_name="isnet-general-use")

    print("--- ëª¨ë“  AI ëª¨ë¸ ë¡œë”© ì™„ë£Œ ---")

@app.on_event("shutdown")
async def shutdown_db_client():
    if database and database.is_connected:
        await database.disconnect()

async def get_db_connection():
    if database and not database.is_connected:
        await database.connect()
    return database

# --- Helper Functions ---
async def get_dog_details(dog_uid: int) -> Dog:
    db = await get_db_connection()
    if not db: raise HTTPException(status_code=500, detail="DB Fail")
    main_query = dogs_table.select().where(dogs_table.c.uid == dog_uid)
    dog_data = await db.fetch_one(main_query)
    if not dog_data: raise HTTPException(status_code=404, detail="Dog Not Found")
    image_query = sub02_table.select().where(sub02_table.c.puid == dog_uid).order_by(sub02_table.c.num)
    image_data_list = await db.fetch_all(image_query)
    image_filenames = [row['s_pic01'] for row in image_data_list]
    return Dog(**dog_data, image_filenames=image_filenames)

def pil_to_cv2(pil_image):
    return cv2.cvtColor(np.array(pil_image), cv2.COLOR_RGB2BGR)

def cv2_to_pil(cv2_image):
    return Image.fromarray(cv2.cvtColor(cv2_image, cv2.COLOR_BGR2RGB))

# í…ìŠ¤íŠ¸ í…Œë‘ë¦¬(Stroke) ê·¸ë¦¬ê¸° í•¨ìˆ˜ 
def draw_text_with_stroke(draw, x, y, text, font, fill_color, stroke_color, stroke_width):
    for dx, dy in [(sx, sy) for sx in range(-stroke_width, stroke_width + 1) for sy in range(-stroke_width, stroke_width + 1) if sx * sx + sy * sy <= stroke_width * stroke_width]:
        draw.text((x + dx, y + dy), text, font=font, fill=stroke_color)
    draw.text((x, y), text, font=font, fill=fill_color)

def get_text_width(draw, text, font):
    max_width = 0
    if not text: return 0
    for line in text.split('\n'):
        try:
            width = draw.textlength(line, font=font)
        except:
            width = len(line) * (font.size * 0.6)
        if width > max_width: max_width = width
    return max_width

def remove_emojis(text):
    if not text: return ""
    return re.sub(r'[^\w\s,.\-?!@#%&()ê°€-í£/]', '', text).strip()

def extract_contact_info(text):
    if not text: return "ë¬¸ì˜: ìì„¸í•œ ë‚´ìš©ì€ ê³µê³  ì›ë¬¸ ì°¸ì¡°"
    insta_id_match = re.search(r'@[a-zA-Z0-9_.]+', text)
    if insta_id_match: return f"ì¸ìŠ¤íƒ€ {insta_id_match.group()}"
    insta_url_match = re.search(r'instagram\.com/([a-zA-Z0-9_.]+)', text)
    if insta_url_match: return f"ì¸ìŠ¤íƒ€ @{insta_url_match.group(1)}"
    url_match = re.search(r'(https?://[^\s]+)', text)
    if url_match:
        if "instagram" in url_match.group(0): return "ì¸ìŠ¤íƒ€ ë§í¬ ì°¸ì¡°"
        return "SNS ë§í¬ ì°¸ì¡°"
    phone_match = re.search(r'010-?[\d]{3,4}-?[\d]{4}', text)
    if phone_match: return f"ë¬¸ì˜ Tel: {phone_match.group()}"
    return "ë¬¸ì˜: ìì„¸í•œ ë‚´ìš©ì€ ê³µê³  ì›ë¬¸ ì°¸ì¡°"

#  (Feathering) í•¨ìˆ˜
def apply_feathering(pil_img, blur_radius=2):
    if pil_img.mode != 'RGBA':
        pil_img = pil_img.convert('RGBA')
    r, g, b, a = pil_img.split()
    # ì•ŒíŒŒ ì±„ë„ì— ë¸”ëŸ¬ì²˜ë¦¬ -> ê²½ê³„ íë¦¿í•˜ê²Œ.
    a_blurred = a.filter(ImageFilter.GaussianBlur(radius=blur_radius))
    return Image.merge("RGBA", (r, g, b, a_blurred))

async def call_sdxl_service(base64_dog_image: str, dog_info: dict) -> Image.Image:
    color_hint = "pastel pink" 
    prompt_detail = f"Minimalist studio background suitable for {dog_info.get('name', 'a dog')}."
    payload = {"base64_dog_image": base64_dog_image, "prompt": prompt_detail, "color_hint": color_hint}
    print(f"Calling SDXL service... Hint: {color_hint}")
    
    async with httpx.AsyncClient(timeout=100.0) as client:
        try:
            response = await client.post(SDXL_SERVICE_URL, json=payload)
            response.raise_for_status()  
            result = response.json()
            base64_bg = result.get("base64_background_image")
            if not base64_bg: raise ValueError("No bg image")
            return Image.open(io.BytesIO(base64.b64decode(base64_bg))).convert("RGB")
        except Exception as e:
            print(f"ğŸš¨ SDXL Error: {e}")
            return Image.new('RGB', (800, 1200), (255, 255, 255))

def generate_dog_text(dog: Dog) -> List[str]: 
    def clean_text(text):
        if not text: return ""
        text = re.sub(r'<[^>]+>', '', text)
        return remove_emojis(text)

    raw_subject = dog.subject if dog.subject else ""
    if '/' in raw_subject: raw_name = raw_subject.split('/')[0] 
    else: raw_name = raw_subject 
    dog_name_only = clean_text(raw_name).strip()
    
    display_age = dog.addinfo05 if dog.addinfo05 and not dog.addinfo05.isdigit() else f"{dog.addinfo05[:4]}ë…„ {dog.addinfo05[4:]}ì›”ìƒ" if dog.addinfo05 and len(dog.addinfo05)==6 else "ì •ë³´ ì—†ìŒ"
    
    basic_info = [
        f"ì´ë¦„: {dog_name_only}",
        f"ì„±ë³„: {clean_text(dog.addinfo03)}",
        f"ì¶œìƒì‹œê¸°: {display_age}", 
        f"ëª¸ë¬´ê²Œ: {clean_text(dog.addinfo07)}kg",
        f"ì¤‘ì„±í™”: {clean_text(dog.addinfo04)}",
    ]
    
    story_data = f"ì´ë¦„:{dog_name_only}, ì„±ê²©:{clean_text(dog.addinfo10)}({clean_text(dog.addinfo08)}), ì‚¬ì—°:{clean_text(dog.addinfo09)}"
    messages = [{"role": "system", "content": "ìœ ê¸°ê²¬ ì…ì–‘ í™ë³´ ë¬¸êµ¬ 2ì¤„ ì‘ì„±. ê°ì„±ì , ê°„ê²°í•˜ê²Œ. ì´ëª¨í‹°ì½˜ ì‚¬ìš© ê¸ˆì§€."}, {"role": "user", "content": f"ì •ë³´: {story_data}"}]
    try:
        client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
        res = client.chat.completions.create(model="gpt-4o-mini", messages=messages, max_tokens=500)
        generated_story = remove_emojis(res.choices[0].message.content.strip()) 
    except:
        generated_story = "ë”°ëœ»í•œ ê°€ì¡±ì„ ê¸°ë‹¤ë¦½ë‹ˆë‹¤."

    contact_source = ""
    if dog.addinfo11: contact_source += dog.addinfo11 
    if dog.addinfo15: contact_source += " " + dog.addinfo15
    if dog.addinfo12: contact_source += " " + dog.addinfo12
    final_contact_info = extract_contact_info(contact_source)

    return basic_info + [generated_story, dog_name_only, final_contact_info] 

#  ì‚¬ì§„ ì„ ë³„ ë¡œì§ ( ì¤‘ì•™ ì§‘ì¤‘)
async def select_best_image(dog: Dog) -> Tuple[Union[Image.Image, None], Union[str, None]]:
    best_img, best_score, best_b64 = None, -999, None
    imgs = [dog.s_pic01] + dog.image_filenames if dog.s_pic01 else dog.image_filenames
    imgs = list(dict.fromkeys([x for x in imgs if x and x.strip()])) # ì¤‘ë³µ ì œê±°
    if not imgs: return None, None
    
    remover_session = models.get("remover")
    print(f"[{dog.uid}] ì´ë¯¸ì§€ ì •ë°€ ì„ ë³„ ì¤‘ ({len(imgs)}ì¥)...")
    
    for fname in imgs:
        try:
            url = f"{SITE_BASE_URL}{IMAGE_BASE_PATH}/{fname}"
            res = requests.get(url, stream=True, timeout=5)
            res.raise_for_status()
            img = Image.open(res.raw).convert("RGB")
            w, h = img.size

            # ì†ë„ë¥¼ ìœ„í•´ ë¦¬ì‚¬ì´ì§• & Alpha Matting OFF
            img_small = img.resize((300, int(300*h/w)))
            no_bg_small = remove(img_small, session=remover_session, alpha_matting=False)
            
            alpha = np.array(no_bg_small.split()[3])
            if cv2.countNonZero(alpha) == 0: continue

            coords = cv2.findNonZero(alpha)
            x, y, box_w, box_h = cv2.boundingRect(coords)
            
            mask_area = box_w * box_h
            total_area = img_small.width * img_small.height
            mask_ratio = mask_area / total_area
            
            score = 0
            
            # 1. í¬ê¸° ì ìˆ˜ (ê½‰ ì°¬ ì‚¬ì§„ ìš°ëŒ€, 10% ë¯¸ë§Œ íƒˆë½)
            if mask_ratio < 0.10: score = -10.0
            else: score += min(mask_ratio * 5.0, 5.0) # í´ìˆ˜ë¡ ì ìˆ˜ (ìµœëŒ€ 5ì )

            # 2. ì¤‘ì•™ ì§‘ì¤‘ë„ ì ìˆ˜
            center_x = x + box_w / 2
            center_y = y + box_h / 2
            img_center_x = img_small.width / 2
            img_center_y = img_small.height / 2
            dist_norm = ((center_x - img_center_x)**2 + (center_y - img_center_y)**2)**0.5
            max_dist = (img_small.width**2 + img_small.height**2)**0.5
            score += (1 - (dist_norm / max_dist)) * 3.0

            # 3. ì„¸ë¡œ ì‚¬ì§„ ìš°ëŒ€
            if h > w: score += 2.0

            # 4. í•˜ë‹¨ ì˜ë¦¼ ì²´í¬ (ë‹¤ë¦¬/ë°œ ì˜ë¦° ì‚¬ì§„ ê°ì )
            if (y + box_h) > (img_small.height * 0.98): score -= 2.0 

            if score > best_score:
                best_score = score
                best_img = img
                buf = io.BytesIO()
                img.save(buf, format="PNG")
                best_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        except: continue
    return best_img, best_b64

# --- ë©”ì¸ API ---
@app.post("/api/v1/generate-real-profile", response_model=dict)
async def generate_real_profile(request: RealProfileRequest):
    if "upsampler" not in models: raise HTTPException(status_code=503, detail="Model Loading")
    dog = await get_dog_details(request.dog_uid)
    best_img, orig_b64 = await select_best_image(dog)
    if not best_img: return {"profile_text": "ì´ë¯¸ì§€ ì—†ìŒ", "profile_image_base64": ""}

    try:
        # 1. Upscaling
        cv2_img = pil_to_cv2(best_img)
        output, _ = models["upsampler"].enhance(cv2_img, outscale=4)
        upscaled_pil = cv2_to_pil(output)
        print("âœ… í™”ì§ˆ ë³µì› ì™„ë£Œ")

        # 2. Background Removal (BiRefNet + Feathering)
        # â­ï¸ alpha_matting=False (ì†ë„) / Feathering (ë¶€ë“œëŸ¬ì›€)
        no_bg = remove(upscaled_pil, session=models["remover"], alpha_matting=False)
        no_bg = apply_feathering(no_bg, blur_radius=2)
        print("âœ… ë°°ê²½ ì œê±° ë° í˜ë”ë§ ì™„ë£Œ")
        
        # 3. SDXL Background
        buf = io.BytesIO()
        no_bg.save(buf, format="PNG")
        b64_png = base64.b64encode(buf.getvalue()).decode("utf-8")
        bg_img = await call_sdxl_service(b64_png, {"name": dog.subject})
        
        # 4. Template Generation
        text_result = generate_dog_text(dog)
        texts = text_result[0:5] 
        story = text_result[5]
        dog_name_only = text_result[6] 
        contact_info = text_result[7]

        template_w, template_h = 1080, 1350
        template = bg_img.resize((template_w, template_h))
        draw = ImageDraw.Draw(template)
        
        try:
            ft = ImageFont.truetype("/app/KyoboHandwriting2021sjy.otf", 80)
            fb = ImageFont.truetype("/app/KyoboHandwriting2021sjy.otf", 38)
            fc = ImageFont.truetype("/app/KyoboHandwriting2021sjy.otf", 30) 
        except: ft = fb = fc = ImageFont.load_default()

        t_txt = f"{dog_name_only}ì˜ ê°€ì¡±ì„ ì°¾ìŠµë‹ˆë‹¤."
        tw = get_text_width(draw, t_txt, ft)
        draw_text_with_stroke(draw, (template_w-tw)/2, 60, t_txt, ft, (255,255,255), (0,0,0), 3)
        
        orig_w, orig_h = no_bg.size
        disp_w = template_w
        disp_h = int(orig_h * (disp_w / orig_w))
        
        MAX_IMG_H = 600
        if disp_h > MAX_IMG_H:
            disp_h = MAX_IMG_H
            disp_w = int(orig_w * (disp_h / orig_h))
        
        paste_img = no_bg.resize((disp_w, disp_h))
        template.paste(paste_img, ((template_w-disp_w)//2, 180), paste_img)
        
        cy = 180 + disp_h + 60
        for i, line in enumerate(texts): 
            w = get_text_width(draw, line, fb)
            draw.text(((template_w-w)/2, cy), line, font=fb, fill=(50,50,50))
            cy += 50 
        
        cy += 30
        for line in textwrap.wrap(story, width=40):
            w = get_text_width(draw, line, fb)
            draw.text(((template_w-w)/2, cy), line, font=fb, fill=(0,0,0))
            cy += 50
            
        # ï¸ SNS/ì—°ë½ì²˜ ì •ë³´ ì¶œë ¥ (í…Œë‘ë¦¬ ì¶”ê°€)
        cw = get_text_width(draw, contact_info, fc)
        draw_text_with_stroke(
            draw, 
            (template_w-cw)/2, 
            template_h - 80, 
            contact_info, 
            fc, 
            (100, 100, 100), # ë‚´ë¶€ ê¸€ì”¨ ìƒ‰ (ì§„í•œ íšŒìƒ‰)
            (255, 255, 255), # í…Œë‘ë¦¬ ìƒ‰ (í°ìƒ‰)
            2
        )

        buf = io.BytesIO()
        template.save(buf, format="PNG")
        final_b64 = base64.b64encode(buf.getvalue()).decode("utf-8")
        return {"profile_text": '\n'.join(texts), "profile_image_base64": final_b64}
        
    except Exception as e:
        print(f"ğŸš¨ Processing Error: {e}")
        return {"profile_text": "Error", "profile_image_base64": orig_b64}
